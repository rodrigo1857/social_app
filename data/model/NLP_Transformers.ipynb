{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e6a8ad1e35b146178bc9bd6137bb7c85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e6525ac052c74c58a5963fd87b7b1277",
              "IPY_MODEL_358d0d0b3c48492ba1f921e875f83359",
              "IPY_MODEL_0c9b24624be34bcb92a883c99f7f4a7a"
            ],
            "layout": "IPY_MODEL_205a74f80f6c428c8b7f27f33db1c41c"
          }
        },
        "e6525ac052c74c58a5963fd87b7b1277": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a1ffdc929ab4f09857fa54f453ccd3c",
            "placeholder": "​",
            "style": "IPY_MODEL_776552c779c4475bb09147b7518e9a4b",
            "value": "Map: 100%"
          }
        },
        "358d0d0b3c48492ba1f921e875f83359": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_95c33355665748f9af77d9dd57235c47",
            "max": 800,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7012e13ad0d84a7592c42115122a1857",
            "value": 800
          }
        },
        "0c9b24624be34bcb92a883c99f7f4a7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e0baa8928e4d4d809a7892cec5ec8616",
            "placeholder": "​",
            "style": "IPY_MODEL_c3018cec1df14960878044dd7207fac5",
            "value": " 800/800 [00:00&lt;00:00, 2410.18 examples/s]"
          }
        },
        "205a74f80f6c428c8b7f27f33db1c41c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a1ffdc929ab4f09857fa54f453ccd3c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "776552c779c4475bb09147b7518e9a4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "95c33355665748f9af77d9dd57235c47": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7012e13ad0d84a7592c42115122a1857": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e0baa8928e4d4d809a7892cec5ec8616": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3018cec1df14960878044dd7207fac5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a12299a5846a44c585e38baa4a7a45ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e05d58c338144d759cea61bba7f8d222",
              "IPY_MODEL_a125478cfba24594b2b9672c2966e5d3",
              "IPY_MODEL_53e91deacb454d5898ac9de22b39c368"
            ],
            "layout": "IPY_MODEL_14d8a2d5b79a48428ebe5318dc1aa3dd"
          }
        },
        "e05d58c338144d759cea61bba7f8d222": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bb42cee3b2304a71abb8e5754bf43e8b",
            "placeholder": "​",
            "style": "IPY_MODEL_6b938d334d994e149bbf28f4e09bf792",
            "value": "Map: 100%"
          }
        },
        "a125478cfba24594b2b9672c2966e5d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_552acbf1aecf4a71a0db81d3d37a5b30",
            "max": 200,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_39ae324e6ac84370bf0a47bf4d66497a",
            "value": 200
          }
        },
        "53e91deacb454d5898ac9de22b39c368": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e276c22c2fab40a58095e861f91673d5",
            "placeholder": "​",
            "style": "IPY_MODEL_200b1e20522440ef840ab09f544a3294",
            "value": " 200/200 [00:00&lt;00:00, 1386.06 examples/s]"
          }
        },
        "14d8a2d5b79a48428ebe5318dc1aa3dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb42cee3b2304a71abb8e5754bf43e8b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b938d334d994e149bbf28f4e09bf792": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "552acbf1aecf4a71a0db81d3d37a5b30": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39ae324e6ac84370bf0a47bf4d66497a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e276c22c2fab40a58095e861f91673d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "200b1e20522440ef840ab09f544a3294": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Fine-tuning a pretrained transformer BERT model for customized sentiment analysis using transformer PyTorch Trainer from Hugging Face"
      ],
      "metadata": {
        "id": "tQqHYsWVTV6D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1: Install And Import Python Libraries"
      ],
      "metadata": {
        "id": "RKQQXSGszh8z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In step 1, we will install and import python libraries.\n",
        "\n",
        "Firstly, let's install `transformers`, `datasets`, and `evaluate`."
      ],
      "metadata": {
        "id": "H2NeMSfdXOAD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install libraries\n",
        "!pip install datasets transformers==4.28.0\n",
        "!pip install transformers datasets evaluate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zhlCxlYWFCHw",
        "outputId": "4a1e4049-ccb7-430d-de41-5e7f2b7d2949"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.14.5)\n",
            "Requirement already satisfied: transformers==4.28.0 in /usr/local/lib/python3.10/dist-packages (4.28.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0) (3.12.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0) (0.16.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0) (2.31.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0) (0.13.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0) (4.66.1)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.3.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec[http]<2023.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.5)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (3.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.28.0) (4.7.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.28.0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.28.0) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.28.0) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.28.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.14.5)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (0.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.16.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.3.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec[http]<2023.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.5)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.18.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (3.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.7.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After installing the python packages, we will import the python libraries.\n",
        "* `pandas` and `numpy` are imported for data processing.\n",
        "* `tensorflow` and `transformers` are imported for modeling.\n",
        "* `Dataset` is imported for the Hugging Face dataset format.\n",
        "* `evaluate` is imported for model performance evaluation."
      ],
      "metadata": {
        "id": "DNcfm6_xfvK4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data processing\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Modeling\n",
        "import tensorflow as tf\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer, EarlyStoppingCallback, TextClassificationPipeline\n",
        "\n",
        "# Hugging Face Dataset\n",
        "from datasets import Dataset\n",
        "\n",
        "# Model performance evaluation\n",
        "import evaluate"
      ],
      "metadata": {
        "id": "4diGKC0ZgETX"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2: Download And Read Data"
      ],
      "metadata": {
        "id": "9zsSYMz72Pj3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The second step is to download and read the dataset.\n",
        "\n",
        "The UCI Machine Learning Repository has the review data from three websites: imdb.com, amazon.com, and yelp.com. We will use the review data from amazon.com for this tutorial. Please follow these steps to download the data.\n",
        "1. Go to: https://archive.ics.uci.edu/ml/datasets/Sentiment+Labelled+Sentences\n",
        "2. Click \"Data Folder\"\n",
        "3. Download \"sentiment labeled sentences.zip\"\n",
        "4. Unzip \"sentiment labeled sentences.zip\"\n",
        "5. Copy the file \"amazon_cells_labelled.txt\" to your project folder"
      ],
      "metadata": {
        "id": "lf9nPi8-2UyC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Change directory\n",
        "import os\n",
        "os.chdir(\"drive/My Drive/contents/nlp\")\n",
        "\n",
        "# Print out the current directory\n",
        "!pwd"
      ],
      "metadata": {
        "id": "vD9lxrv52eKU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33a16454-9562-4320-9986-a8ae6ae3f92e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/My Drive/contents/nlp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's read the data into a `pandas` dataframe and see what the dataset looks like.\n",
        "\n",
        "The dataset has two columns. One column contains the reviews and the other column contains the sentiment label for the review."
      ],
      "metadata": {
        "id": "KKQzJp0V3I2Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read in data\n",
        "amz_review = pd.read_csv('sentiment labelled sentences/amazon_cells_labelled.txt', sep='\\t', names=['review', 'label'])\n",
        "\n",
        "# Take a look at the data\n",
        "amz_review.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "iHeaTdXC3KF0",
        "outputId": "14af6e5c-fdeb-48ef-a192-d77457045d2e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              review  label\n",
              "0  So there is no way for me to plug it in here i...      0\n",
              "1                        Good case, Excellent value.      1\n",
              "2                             Great for the jawbone.      1\n",
              "3  Tied to charger for conversations lasting more...      0\n",
              "4                                  The mic is great.      1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-99f8a6c3-4e61-4b11-9f77-90de99e28182\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>So there is no way for me to plug it in here i...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Good case, Excellent value.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Great for the jawbone.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Tied to charger for conversations lasting more...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The mic is great.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-99f8a6c3-4e61-4b11-9f77-90de99e28182')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-99f8a6c3-4e61-4b11-9f77-90de99e28182 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-99f8a6c3-4e61-4b11-9f77-90de99e28182');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-80c882f1-b55a-4614-9ab2-58f7008a8d94\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-80c882f1-b55a-4614-9ab2-58f7008a8d94')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-80c882f1-b55a-4614-9ab2-58f7008a8d94 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the dataset information\n",
        "amz_review.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FhFS5XPxNoRw",
        "outputId": "bd68053e-f7a7-4ff9-a8eb-6f84ee0fde8d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1000 entries, 0 to 999\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   review  1000 non-null   object\n",
            " 1   label   1000 non-null   int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 15.8+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The label value of 0 represents negative reviews and the label value of 1 represents positive reviews. The dataset has 500 positive reviews and 500 negative reviews. It is well-balanced, so we can use  accuracy as the metric to evaluate the model performance."
      ],
      "metadata": {
        "id": "6VMuoMFwnMbV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the label distribution\n",
        "amz_review['label'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16rB8tdEaYX1",
        "outputId": "dc626062-3e2b-4e02-80ac-37874726c5f1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    500\n",
              "1    500\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3: Train Test Split"
      ],
      "metadata": {
        "id": "J2rfMma3Smh7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In step 3, we will split the dataset and have 80% as the training dataset and 20% as the testing dataset.\n",
        "\n",
        "Using the `sample` method, we set `frac=0.8`, which randomly samples 80% of the data. `random_state=42` ensures that the sampling result is reproducible.\n",
        "\n",
        "Dropping the `train_data` from the review dataset gives us the rest 20% of the data, which is our testing dataset."
      ],
      "metadata": {
        "id": "BM7ZEjUCVyv3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training dataset\n",
        "train_data = amz_review.sample(frac=0.8, random_state=42)\n",
        "\n",
        "# Testing dataset\n",
        "test_data = amz_review.drop(train_data.index)\n",
        "\n",
        "# Check the number of records in training and testing dataset.\n",
        "print(f'The training dataset has {len(train_data)} records.')\n",
        "print(f'The testing dataset has {len(test_data)} records.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PaFydZD5BHqO",
        "outputId": "080e619d-e294-4f87-f2f4-4b6dedd33ded"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The training dataset has 800 records.\n",
            "The testing dataset has 200 records.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After the train test split, there are 800 reviews in the training dataset and 200 reviews in the testing dataset."
      ],
      "metadata": {
        "id": "aP1XBRjRWtfX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 4: Convert Pandas Dataframe to Hugging Face Dataset"
      ],
      "metadata": {
        "id": "s7_KrZL1E5pH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In step 4, the training and the testing datasets will be converted from pandas dataframe to Hugging Face Dataset format.\n",
        "\n",
        "Hugging Face Dataset objects are memory-mapped on drive, so they are not limited by RAM memory, which is very helpful for processing large datasets.\n",
        "\n",
        "We use `Dataset.from_pandas` to convert a pandas dataframe to a Hugging Face Dataset."
      ],
      "metadata": {
        "id": "5wL7euXiEwEw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert pyhton dataframe to Hugging Face arrow dataset\n",
        "hg_train_data = Dataset.from_pandas(train_data)\n",
        "hg_test_data = Dataset.from_pandas(test_data)"
      ],
      "metadata": {
        "id": "JM0CjSK7DFWi"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The length of the Hugging Face Dataset is the same as the number of records in the pandas dataframe. For example, there are 800 records in the pandas dataframe for the training dataset, and the length of the converted Hugging Face Dataset for the training dataset is 800 too.\n",
        "\n",
        "`hg_train_data[0]` gives us the first record in the Hugging Face Dataset. It is a dictionary with three keys, `review`, `label`, and `__index_level_0__`.\n",
        "* `review` is the variable name for the review text. The name is inherited from the column name of the pandas dataframe.\n",
        "* `label` is the variable name for the sentiment of the review text. The name is inherited from the column name of the pandas dataframe too.\n",
        "* `__index_level_0__` is an automatically generated field from the pandas dataframe. It stores the index of the corresponding record."
      ],
      "metadata": {
        "id": "ljaWzXG-PEpM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Length of the Dataset\n",
        "print(f'The length of hg_train_data is {len(hg_train_data)}.\\n')\n",
        "\n",
        "# Check one review\n",
        "hg_train_data[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tdWpRd5KKqIB",
        "outputId": "af9a23a5-b1ff-41bf-89c3-769a6fec304c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The length of hg_train_data is 800.\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'review': 'Thanks again to Amazon for having the things I need for a good price!',\n",
              " 'label': 1,\n",
              " '__index_level_0__': 521}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this example, we can see that the review is `Thanks again to Amazon for having the things I need for a good price!`, the sentiment for the review is positive/1, and the index of this record is 521 in the pandas dataframe.\n",
        "\n",
        "Checking the index 521 in the pandas dataframe confirms the same information with Hugging Face Dataset."
      ],
      "metadata": {
        "id": "pIGEczo3SpYd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Validate the record in pandas dataframe\n",
        "amz_review.iloc[[521]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "uiQBYYZtOJHa",
        "outputId": "b7e43bb5-a1fc-4706-db62-6157fa186467"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                review  label\n",
              "521  Thanks again to Amazon for having the things I...      1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-488882f4-84f1-4646-bb9a-6c61116274f9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>521</th>\n",
              "      <td>Thanks again to Amazon for having the things I...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-488882f4-84f1-4646-bb9a-6c61116274f9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-488882f4-84f1-4646-bb9a-6c61116274f9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-488882f4-84f1-4646-bb9a-6c61116274f9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 5: Tokenize Text"
      ],
      "metadata": {
        "id": "e596ZDPLB2a5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In step 5, we will tokenize the review text using a tokenizer.\n",
        "\n",
        "A tokenizer converts text into numbers to use as the input of the NLP (Natural Language Processing) models. Each number represents a token, which can be a word, part of a word, punctuation, or special tokens. How the text is tokenized is determined by the pretrained model. `AutoTokenizer.from_pretrained(\"bert-base-cased\")` is used to download vocabulary from the pretrained `bert-base-cased` model, meaning that the text will be tokenized like a BERT model."
      ],
      "metadata": {
        "id": "ccd3KQcZwpFN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenizer from a pretrained model\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
        "\n",
        "# Take a look at the tokenizer\n",
        "tokenizer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uYVxGawWwsIS",
        "outputId": "0c4060d4-7373-4cda-d037-5dcb2821827b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertTokenizerFast(name_or_path='bert-base-cased', vocab_size=28996, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that the tokenizer contains information such as model name, vocabulary size, max length, padding position, truncation position, and special tokens.\n",
        "\n",
        "There are five special tokens for the BERT model. Other models may have different special tokens.\n",
        " * The tokens that are not part of the BERT model training dataset are unknown tokens. The unknown token is [UNK] and the ID for the unknown token is 100.\n",
        " * The separator token is [SEP] and the ID for the separator token is 102.\n",
        " * The pad token is [PAD] and the ID for the pad token is 0.\n",
        " * The sentence level classification token is [CLS] and the ID for the classification token is 101.\n",
        " * The mask token is [MASK] and the ID for the mask token is 103."
      ],
      "metadata": {
        "id": "OFGCx-PWw7yN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mapping between special tokens and their IDs.\n",
        "print(f'The unknown token is {tokenizer.unk_token} and the ID for the unkown token is {tokenizer.unk_token_id}.')\n",
        "print(f'The seperator token is {tokenizer.sep_token} and the ID for the seperator token is {tokenizer.sep_token_id}.')\n",
        "print(f'The pad token is {tokenizer.pad_token} and the ID for the pad token is {tokenizer.pad_token_id}.')\n",
        "print(f'The sentence level classification token is {tokenizer.cls_token} and the ID for the classification token is {tokenizer.cls_token_id}.')\n",
        "print(f'The mask token is {tokenizer.mask_token} and the ID for the mask token is {tokenizer.mask_token_id}.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y47m2Z6_wtyU",
        "outputId": "c20015f5-0ec0-4a19-c044-388275d23d43"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The unknown token is [UNK] and the ID for the unkown token is 100.\n",
            "The seperator token is [SEP] and the ID for the seperator token is 102.\n",
            "The pad token is [PAD] and the ID for the pad token is 0.\n",
            "The sentence level classification token is [CLS] and the ID for the classification token is 101.\n",
            "The mask token is [MASK] and the ID for the mask token is 103.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After downloading the model vocabulary, the method `tokenizer` is used to tokenize the review corpus.\n",
        "* `max_length` indicates the maximum number of tokens kept for each document.\n",
        " * If the document has more tokens than the `max_length`, it will be truncated.\n",
        " * If the document has less tokens than the `max_length`, it will be padded with zeros.\n",
        " * If `max_length` is unset or set to `None`, the maximum length from the pretrained model will be used. If the pretrained model does not have a maximum length parameter, `max_length` will be deactivated.\n",
        "* `truncation` controls how the token truncation is implemented. `truncation=True` indicates that the truncation length is the length specified by `max_length`. If `max_length` is not specified, the max_length of the pretrained model is used.\n",
        "* `padding` means adding zeros to shorter reviews in the dataset. The `padding` argument controls how `padding` is conducted.  \n",
        " * `padding=True` is the same as `padding='longest'`. It checks the longest sequence in the batch and pads zeros to that length. There is no padding if only one text document is provided.\n",
        " * `padding='max_length'` pads to `max_length` if it is specified, otherwise, it pads to the maximum acceptable input length for the model.\n",
        " * `padding=False` is the same as `padding='do_not_pad'`. It is the default, indicating that no padding is applied, so it can output a batch with sequences of different lengths."
      ],
      "metadata": {
        "id": "jgF67x23W6y2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Funtion to tokenize data\n",
        "def tokenize_dataset(data):\n",
        "    return tokenizer(data[\"review\"],\n",
        "                     max_length=32,\n",
        "                     truncation=True,\n",
        "                     padding=\"max_length\")\n",
        "\n",
        "# Tokenize the dataset\n",
        "dataset_train = hg_train_data.map(tokenize_dataset)\n",
        "dataset_test = hg_test_data.map(tokenize_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "e6a8ad1e35b146178bc9bd6137bb7c85",
            "e6525ac052c74c58a5963fd87b7b1277",
            "358d0d0b3c48492ba1f921e875f83359",
            "0c9b24624be34bcb92a883c99f7f4a7a",
            "205a74f80f6c428c8b7f27f33db1c41c",
            "4a1ffdc929ab4f09857fa54f453ccd3c",
            "776552c779c4475bb09147b7518e9a4b",
            "95c33355665748f9af77d9dd57235c47",
            "7012e13ad0d84a7592c42115122a1857",
            "e0baa8928e4d4d809a7892cec5ec8616",
            "c3018cec1df14960878044dd7207fac5",
            "a12299a5846a44c585e38baa4a7a45ac",
            "e05d58c338144d759cea61bba7f8d222",
            "a125478cfba24594b2b9672c2966e5d3",
            "53e91deacb454d5898ac9de22b39c368",
            "14d8a2d5b79a48428ebe5318dc1aa3dd",
            "bb42cee3b2304a71abb8e5754bf43e8b",
            "6b938d334d994e149bbf28f4e09bf792",
            "552acbf1aecf4a71a0db81d3d37a5b30",
            "39ae324e6ac84370bf0a47bf4d66497a",
            "e276c22c2fab40a58095e861f91673d5",
            "200b1e20522440ef840ab09f544a3294"
          ]
        },
        "id": "0Pxclwx2qfk9",
        "outputId": "de543d1e-39b5-4666-ebfb-a3855cafe294"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/800 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e6a8ad1e35b146178bc9bd6137bb7c85"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a12299a5846a44c585e38baa4a7a45ac"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After tokenization, we can see that both the training and the testing Dataset have 6 features, `'review'`, `'label'`, `'__index_level_0__'`, `'input_ids'`, `'token_type_ids'`, and `'attention_mask'`. The number of rows is stored with `num_rows`."
      ],
      "metadata": {
        "id": "I7HKyIjbb0Sh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Take a look at the data\n",
        "print(dataset_train)\n",
        "print(dataset_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8b7EQgtoJzH",
        "outputId": "65a55385-6da2-451d-8716-fc67c638457a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset({\n",
            "    features: ['review', 'label', '__index_level_0__', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
            "    num_rows: 800\n",
            "})\n",
            "Dataset({\n",
            "    features: ['review', 'label', '__index_level_0__', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
            "    num_rows: 200\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`dataset_train[0]` gives us the content for the first record in the training dataset in a dictionary format.\n",
        "* `'review'` has the review text. The first review of the training dataset is `'Thanks again to Amazon for having the things I need for a good price!'`.\n",
        "* `'label'` is the label of the classification. The first record is a positive review, so the label is 1.\n",
        "* `'__index_level_0__'` is the index of the record. 521 means that the first record in the training dataset has the index 521 in the original pandas dataframe.\n",
        "* `'input_ids'` are the IDs for the tokens. There are 32 token IDs because the `max_length` is 32 for the tokenization.\n",
        "* `'token_type_ids'` is also called segment IDs.\n",
        " * BERT was trained on two tasks, Masked Language Modeling and Next Sentence Prediction. `'token_type_ids'` is for the Next Sentence Prediction, where two sentences are used to predict whether the second sentence is the next sentence for the first one.\n",
        " * The first sentence has all the tokens represented by zeros, and the second sentence has all the tokens represented by ones.\n",
        " * Because our classification task does not have a second sentence, all the values for `'token_type_ids'` are zeros.\n",
        "* `'attention_mask'` indicates which token ID should get attention from the model, so the padding tokens are all zeros and other tokens are 1s.\n",
        "\n"
      ],
      "metadata": {
        "id": "oan104mCphW7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the first record\n",
        "dataset_train[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gCodao7MoQt-",
        "outputId": "2ea49ef9-4d7e-42d7-ef5f-f26d68fb8e8c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'review': 'Thanks again to Amazon for having the things I need for a good price!',\n",
              " 'label': 1,\n",
              " '__index_level_0__': 521,\n",
              " 'input_ids': [101,\n",
              "  5749,\n",
              "  1254,\n",
              "  1106,\n",
              "  9786,\n",
              "  1111,\n",
              "  1515,\n",
              "  1103,\n",
              "  1614,\n",
              "  146,\n",
              "  1444,\n",
              "  1111,\n",
              "  170,\n",
              "  1363,\n",
              "  3945,\n",
              "  106,\n",
              "  102,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0],\n",
              " 'token_type_ids': [0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0],\n",
              " 'attention_mask': [1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0]}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 6: Load Pretrained Model"
      ],
      "metadata": {
        "id": "pInnpLnyZ0xF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In step 6, we will load the pretrained model for sentiment analysis.\n",
        "\n",
        "* `AutoModelForSequenceClassification` loads the BERT model without the sequence classification head.\n",
        "* The method `from_pretrained()` loads the weights from the pretrained model into the new model, so the weights in the new model are not randomly initialized. Note that the new weights for the new sequence classification head are going to be randomly initialized.\n",
        "* `bert-base-cased` is the name of the pretrained model. We can change it to a different model based on the nature of the project.\n",
        "* `num_labels` indicates the number of classes. Our dataset has two classes, positive and negative, so `num_labels=2`."
      ],
      "metadata": {
        "id": "mKw8n6QsnstR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "alXwU9ylqGSR",
        "outputId": "1d501814-18f9-4d00-f3b3-cecd412908aa"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 7: Set Training Argument"
      ],
      "metadata": {
        "id": "c5SRFC8b0QIm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In step 7, we will set the training arguments for the model.\n",
        "\n",
        "Hugging Face has 96 parameters for `TrainingArguments`, which provides a lot of flexibility in fine-tuning the transfer learning model.\n",
        "* `output_dir` is the directory to write the model checkpoints and model predictions.\n",
        "* `logging_dir` is the directory for saving logs.\n",
        "* `logging_strategy` is the strategy for logging the training information.\n",
        " * `'no'` means no logging for the training.\n",
        " * `'epoch'` means logging at the end of each epoch.\n",
        " * `'steps'` means logging at the end of each `logging_steps`.\n",
        "* `logging_steps` is the number of steps between two logs. The default is 500.\n",
        "* `num_train_epochs` is the total number of training epochs. The default value is 3.\n",
        "* `per_device_train_batch_size` is the batch size per GPU/TPU core/CPU for training. The default value is 8.\n",
        "* `per_device_eval_batch_size` is the batch size per GPU/TPU core/CPU for evaluation. The default value is 8.\n",
        "* `learning_rate` is the initial learning rate for AdamW optimizer. The default value is 5e-5.\n",
        "* `seed` is for reproducibility.\n",
        "* `save_strategy` is the strategy for saving the checkpoint during training.\n",
        " * `'no'` means do not save during training.\n",
        " * `'epoch'` means saving at the end of each epoch.\n",
        " * `'steps'` means saving at the end of each `save_steps`. `'steps'` is the default value.\n",
        "* `save_steps` is the number of steps before two checkpoint saves. The default value is 500.\n",
        "* `evaluation_strategy` is the strategy for evaluation during training. It's helpful for us to monitor the model performance during model fine-tuning.\n",
        " * `'no'` means no evaluation during training.\n",
        " * `'epoch'` means evaluating at the end of each epoch and the evaluation results will be printed out at the end of each epoch.\n",
        " * `'steps'` means evaluating and reporting at the end of each `eval_steps`. `'no'` is the default value.\n",
        "* `eval_steps` is the number of steps between two evaluations if `evaluation_strategy='steps'`. It defaults to the same value as `logging_steps` if not set.\n",
        "* `load_best_model_at_end=True` indicates that the best model will be loaded at the end of the training. The default is `False`. When it is set to `True`, the `save_strategy` and `evaluation_strategy` must be the same. When both arguments are `'steps'`, the value of `save_steps` needs to be a round multiple of the value of `eval_steps`."
      ],
      "metadata": {
        "id": "xrTVGiENPznD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./sentiment_transfer_learning_transformer/\",\n",
        "    logging_dir='./sentiment_transfer_learning_transformer/logs',\n",
        "    logging_strategy='epoch',\n",
        "    logging_steps=100,\n",
        "    num_train_epochs=2,\n",
        "    per_device_train_batch_size=4,\n",
        "    per_device_eval_batch_size=4,\n",
        "    learning_rate=5e-6,\n",
        "    seed=42,\n",
        "    save_strategy='epoch',\n",
        "    save_steps=100,\n",
        "    evaluation_strategy='epoch',\n",
        "    eval_steps=100,\n",
        "    load_best_model_at_end=True\n",
        ")"
      ],
      "metadata": {
        "id": "aoM8kA7xv61O"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 8: Set Evaluation Metrics"
      ],
      "metadata": {
        "id": "lLAPSRzVNHYH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In step 8, we will set the evaluation metric because Hugging Face Trainer does not evaluate the model performance automatically during the training process.\n",
        "\n",
        "Hugging Face has an `evaluate` library with over 100 evaluation modules. We can see the list of all the modules using `evaluate.list_evaluation_modules()`."
      ],
      "metadata": {
        "id": "uz6C-lCncrJb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of evaluation modules\n",
        "print(f'There are {len(evaluate.list_evaluation_modules())} evaluation models in Hugging Face.\\n')\n",
        "\n",
        "# List all evaluation metrics\n",
        "evaluate.list_evaluation_modules()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X0cir3_DYCkr",
        "outputId": "fd90d7ad-a968-45cd-e903-432905ba13b2"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 138 evaluation models in Hugging Face.\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['precision',\n",
              " 'code_eval',\n",
              " 'roc_auc',\n",
              " 'cuad',\n",
              " 'xnli',\n",
              " 'rouge',\n",
              " 'pearsonr',\n",
              " 'mse',\n",
              " 'super_glue',\n",
              " 'comet',\n",
              " 'cer',\n",
              " 'sacrebleu',\n",
              " 'mahalanobis',\n",
              " 'wer',\n",
              " 'competition_math',\n",
              " 'f1',\n",
              " 'recall',\n",
              " 'coval',\n",
              " 'mauve',\n",
              " 'xtreme_s',\n",
              " 'bleurt',\n",
              " 'ter',\n",
              " 'accuracy',\n",
              " 'exact_match',\n",
              " 'indic_glue',\n",
              " 'spearmanr',\n",
              " 'mae',\n",
              " 'squad',\n",
              " 'chrf',\n",
              " 'glue',\n",
              " 'perplexity',\n",
              " 'mean_iou',\n",
              " 'squad_v2',\n",
              " 'meteor',\n",
              " 'bleu',\n",
              " 'wiki_split',\n",
              " 'sari',\n",
              " 'frugalscore',\n",
              " 'google_bleu',\n",
              " 'bertscore',\n",
              " 'matthews_correlation',\n",
              " 'seqeval',\n",
              " 'trec_eval',\n",
              " 'rl_reliability',\n",
              " 'angelina-wang/directional_bias_amplification',\n",
              " 'cpllab/syntaxgym',\n",
              " 'kaggle/ai4code',\n",
              " 'codeparrot/apps_metric',\n",
              " 'mfumanelli/geometric_mean',\n",
              " 'poseval',\n",
              " 'brier_score',\n",
              " 'abidlabs/mean_iou',\n",
              " 'abidlabs/mean_iou2',\n",
              " 'giulio98/codebleu',\n",
              " 'mase',\n",
              " 'mape',\n",
              " 'smape',\n",
              " 'dvitel/codebleu',\n",
              " 'NCSOFT/harim_plus',\n",
              " 'JP-SystemsX/nDCG',\n",
              " 'Drunper/metrica_tesi',\n",
              " 'jpxkqx/peak_signal_to_noise_ratio',\n",
              " 'jpxkqx/signal_to_reconstruction_error',\n",
              " 'hpi-dhc/FairEval',\n",
              " 'nist_mt',\n",
              " 'lvwerra/accuracy_score',\n",
              " 'character',\n",
              " 'charcut_mt',\n",
              " 'ybelkada/cocoevaluate',\n",
              " 'harshhpareek/bertscore',\n",
              " 'posicube/mean_reciprocal_rank',\n",
              " 'bstrai/classification_report',\n",
              " 'omidf/squad_precision_recall',\n",
              " 'Josh98/nl2bash_m',\n",
              " 'BucketHeadP65/confusion_matrix',\n",
              " 'BucketHeadP65/roc_curve',\n",
              " 'yonting/average_precision_score',\n",
              " 'transZ/test_parascore',\n",
              " 'transZ/sbert_cosine',\n",
              " 'hynky/sklearn_proxy',\n",
              " 'unnati/kendall_tau_distance',\n",
              " 'r_squared',\n",
              " 'Viona/fuzzy_reordering',\n",
              " 'Viona/kendall_tau',\n",
              " 'lhy/hamming_loss',\n",
              " 'lhy/ranking_loss',\n",
              " 'Muennighoff/code_eval_octopack',\n",
              " 'yuyijiong/quad_match_score',\n",
              " 'Splend1dchan/cosine_similarity',\n",
              " 'AlhitawiMohammed22/CER_Hu-Evaluation-Metrics',\n",
              " 'Yeshwant123/mcc',\n",
              " 'transformersegmentation/segmentation_scores',\n",
              " 'sma2023/wil',\n",
              " 'chanelcolgate/average_precision',\n",
              " 'ckb/unigram',\n",
              " 'Felipehonorato/eer',\n",
              " 'manueldeprada/beer',\n",
              " 'tialaeMceryu/unigram',\n",
              " 'He-Xingwei/sari_metric',\n",
              " 'langdonholmes/cohen_weighted_kappa',\n",
              " 'fschlatt/ner_eval',\n",
              " 'hyperml/balanced_accuracy',\n",
              " 'brian920128/doc_retrieve_metrics',\n",
              " 'guydav/restrictedpython_code_eval',\n",
              " 'k4black/codebleu',\n",
              " 'Natooz/ece',\n",
              " 'ingyu/klue_mrc',\n",
              " 'Vipitis/shadermatch',\n",
              " 'unitxt/metric',\n",
              " 'gabeorlanski/bc_eval',\n",
              " 'jjkim0807/code_eval',\n",
              " 'vichyt/metric-codebleu',\n",
              " 'fastrepl/mean_reciprocal_rank',\n",
              " 'fastrepl/mean_average_precision',\n",
              " 'mtc/fragments',\n",
              " 'DarrenChensformer/eval_keyphrase',\n",
              " 'kedudzic/charmatch',\n",
              " 'agkhalil/ragene_metrics',\n",
              " 'eperezfmit/my_metric',\n",
              " 'eperezfmit/my_metric_3',\n",
              " 'mcnemar',\n",
              " 'exact_match',\n",
              " 'wilcoxon',\n",
              " 'kaleidophon/almost_stochastic_order',\n",
              " 'word_length',\n",
              " 'lvwerra/element_count',\n",
              " 'word_count',\n",
              " 'text_duplicates',\n",
              " 'perplexity',\n",
              " 'label_distribution',\n",
              " 'toxicity',\n",
              " 'regard',\n",
              " 'honest',\n",
              " 'ybelkada/toxicity',\n",
              " 'ronaldahmed/ccl_win',\n",
              " 'meg/perplexity',\n",
              " 'cakiki/tokens_per_byte',\n",
              " 'lsy641/distinct']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since our dataset is highly balanced, we will use accuracy as the evaluation metric. It can be loaded using `evaluate.load(\"accuracy\")`. After getting predictions from the model, the metric is computed using `metric.compute`."
      ],
      "metadata": {
        "id": "56L2AZe4eroE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to compute the metric\n",
        "def compute_metrics(eval_pred):\n",
        "    metric = evaluate.load(\"accuracy\")\n",
        "    logits, labels = eval_pred\n",
        "    # probabilities = tf.nn.softmax(logits)\n",
        "    predictions = np.argmax(logits, axis=1)\n",
        "    return metric.compute(predictions=predictions, references=labels)"
      ],
      "metadata": {
        "id": "Pljt8VLCNJFR"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 9: Train Model Using Transformer Trainer"
      ],
      "metadata": {
        "id": "m2Oxt0KtOqPY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In step 9, we will train the model using the transformer `Trainer`.\n",
        "* model is the model for training, evaluation, or prediction by the `Trainer`.\n",
        "* `args` takes the arguments for tweaking the `Trainer`. It defaults to the instance of `TrainingArguments`.\n",
        "* `train_dataset` is the training dataset name. If the dataset is in `Dataset` format, the unused columns will be automatically ignored. In our training dataset, `__index_level_0__` and `review` are not used by the model, so they are ignored.\n",
        "* `eval_dataset` is the evaluation dataset name. Similar to the `train_dataset`, the unused columns will be automatically ignored for the `Dataset` format.\n",
        "* `compute_metrics` takes the function for calculating evaluation metrics.\n",
        "* `callbacks` takes a list of callbacks to customize the training loop. `EarlyStoppingCallback` stops the training by `early_stopping_patience` for the evaluation calls. There is no practical need to use early stopping because there are only two epochs for the model. It is included as an example code reference."
      ],
      "metadata": {
        "id": "3SXRUZ6I1Sq6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=dataset_train,\n",
        "    eval_dataset=dataset_test,\n",
        "    compute_metrics=compute_metrics,\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=1)]\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "id": "3LHAlFU_6-IF",
        "outputId": "1b29618a-74c1-44a5-f476-d1a12a627596"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='9' max='400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [  9/400 00:17 < 16:21, 0.40 it/s, Epoch 0.04/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that the accuracy is above 90 percent in just 2 epochs."
      ],
      "metadata": {
        "id": "wz5H-O5Y80zK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 10: Make Predictions for Text Classification"
      ],
      "metadata": {
        "id": "QqiOoAD-yGKM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In step 10, we will talk about how to make predictions using the Hugging Face transformer Trainer model.\n",
        "\n",
        "Passing the tokenized `Dataset` to the `.predict` method, we get the predictions for the customized transfer learning sentiment model. We can see that the prediction results contain multiple pieces of information.\n",
        "* `Num examples = 200` indicates that there are 200 reviews in the testing dataset.\n",
        "* `Batch size = 4` means that 4 reviews are processed each time.\n",
        "* Under `PredictionOutput`, `predictions` has the logits for each class. logit is the last layer of the neural network before softmax is applied. `label_ids` has the actual labels. Please note that it is not predicted labels although it is under the `PredictionOutput`. We need to calculate the predicted labels based on the logit values.\n",
        "* Under `metrics` there is information about the testing predictions.\n",
        " * `test_loss` is the loss for the testing dataset.  \n",
        " * `test_accuracy` is the percentage of correct predictions.\n",
        " * `test_runtime` is the runtime for testing.\n",
        " * `test_samples_per_second` is the number of samples the model can process in one second.\n",
        " * `test_steps_per_second` is the number of steps the model can process in one second.\n"
      ],
      "metadata": {
        "id": "vtXo_gGFgm3F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predictions\n",
        "y_test_predict = trainer.predict(dataset_test)\n",
        "\n",
        "# Take a look at the predictions\n",
        "y_test_predict"
      ],
      "metadata": {
        "id": "p1jk8PSQgbhS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The predicted logits for the transfer learning text classification model can be extracted using `.predictions`."
      ],
      "metadata": {
        "id": "d9y3EfeO-8yN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that the prediction has two columns. The first column is the predicted logit for label 0 and the second column is the predicted logit for label 1. logit values do not sum up to 1."
      ],
      "metadata": {
        "id": "VmcAlpnl_hJF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicted logits\n",
        "y_test_logits = y_test_predict.predictions\n",
        "\n",
        "# First 5 predicted probabilities\n",
        "y_test_logits[:5]"
      ],
      "metadata": {
        "id": "N_HSPkZAminc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To get the predicted probabilities, we need to apply softmax on the predicted logit values."
      ],
      "metadata": {
        "id": "Ge6rXFhY_kGc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "After applying softmax, we can see that the predicted probability for each review sums up to 1."
      ],
      "metadata": {
        "id": "BU5JrMyZ_0GY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicted probabilities\n",
        "y_test_probabilities = tf.nn.softmax(y_test_logits)\n",
        "\n",
        "# First 5 predicted logits\n",
        "y_test_probabilities[:5]"
      ],
      "metadata": {
        "id": "ow4uX4Jv_srX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To get the predicted labels, `argmax` is used to return the index of the maximum probability for each review, which corresponds to the labels of zeros and ones."
      ],
      "metadata": {
        "id": "FyFbba9R_7ko"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicted labels\n",
        "y_test_pred_labels = np.argmax(y_test_probabilities, axis=1)\n",
        "\n",
        "# First 5 predicted probabilities\n",
        "y_test_pred_labels[:5]"
      ],
      "metadata": {
        "id": "1I0mQBmO4drn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The actual labels can be extracted using `y_test_predict.label_ids`."
      ],
      "metadata": {
        "id": "oBkMRVTx_-pT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Actual labels\n",
        "y_test_actual_labels = y_test_predict.label_ids\n",
        "\n",
        "# First 5 predicted probabilities\n",
        "y_test_actual_labels[:5]"
      ],
      "metadata": {
        "id": "bOdI273Xmt9_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 11: Model Performance Evaluation"
      ],
      "metadata": {
        "id": "lBhVxzzNqn13"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In step 11, we will make the transfer learning text classification model performance evaluation.\n",
        "\n",
        "`trainer.evaluate` is a quick way to get the loss and the accuracy of the testing dataset."
      ],
      "metadata": {
        "id": "L4jmMaJbAK7K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that the model has a loss of 0.28 and an accuracy of 91.5%."
      ],
      "metadata": {
        "id": "2gj7Sr1lCD3T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Trainer evaluate\n",
        "trainer.evaluate(dataset_test)"
      ],
      "metadata": {
        "id": "0S8AKdc2Bm0Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To calculate more model performance metrics, we can use `evaluate.load` to load the metrics of interest."
      ],
      "metadata": {
        "id": "__cIM_jjCT3x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The results show that the testing dataset has a `f1` value of 0.91 and a `recall` value of 0.89."
      ],
      "metadata": {
        "id": "M-X-JB4Qlcbs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load f1 metric\n",
        "metric_f1 = evaluate.load(\"f1\")\n",
        "\n",
        "# Compute f1 metric\n",
        "metric_f1.compute(predictions=y_test_pred_labels, references=y_test_actual_labels)"
      ],
      "metadata": {
        "id": "VaeNxx0l4rpk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load recall metric\n",
        "metric_recall = evaluate.load(\"recall\")\n",
        "\n",
        "# Compute recall metric\n",
        "metric_recall.compute(predictions=y_test_pred_labels, references=y_test_actual_labels)"
      ],
      "metadata": {
        "id": "x_jMEh-wrn00"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 12: Save and Load Model"
      ],
      "metadata": {
        "id": "33BZbt5FwTL0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In step 12, we will talk about how to save the model and reload it for prediction.\n",
        "\n",
        "`tokenizer.save_pretrained` saves the tokenizer information to the drive and `model.save_model` saves the model to the drive."
      ],
      "metadata": {
        "id": "xI54T7SWSEKv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save tokenizer\n",
        "tokenizer.save_pretrained('./sentiment_transfer_learning_transformer/')\n",
        "\n",
        "# Save model\n",
        "trainer.save_model('./sentiment_transfer_learning_transformer/')"
      ],
      "metadata": {
        "id": "phvsc3K47X-c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can load the saved tokenizer later using `AutoTokenizer.from_pretrained()` and load the saved model using `AutoModelForSequenceClassification.from_pretrained()`."
      ],
      "metadata": {
        "id": "qH2KqgCXSxcc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"./sentiment_transfer_learning_transformer/\")\n",
        "\n",
        "# Load model\n",
        "loaded_model = AutoModelForSequenceClassification.from_pretrained('./sentiment_transfer_learning_transformer/')"
      ],
      "metadata": {
        "id": "rTSztSdeYwnP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}